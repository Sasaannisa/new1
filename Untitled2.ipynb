{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n"
     ]
    }
   ],
   "source": [
    "#Module\n",
    "%matplotlib\n",
    "import pandas as pd\n",
    "from pandas.tools import plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split,cross_val_score, KFold, GridSearchCV \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier,export_graphviz\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier,RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#IMPORT DATA\n",
    "kredit=pd.read_csv('F:/Semester 3/Studi Kasus/cc2_new.csv', sep=';')\n",
    "kredit1 = kredit.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 16625 entries, 0 to 16624\n",
      "Data columns (total 16 columns):\n",
      "ID           16625 non-null int64\n",
      "TARGET       16625 non-null int64\n",
      "AGE          16625 non-null int64\n",
      "LIMIT_BAL    16625 non-null float64\n",
      "MARRIAGE     16625 non-null int64\n",
      "EDUCATION    16625 non-null int64\n",
      "SEX          16625 non-null int64\n",
      "PAY_1        16625 non-null int64\n",
      "PAY_2        16625 non-null int64\n",
      "PAY_3        16625 non-null int64\n",
      "PAY_AMT1     16625 non-null float64\n",
      "PAY_AMT2     16625 non-null float64\n",
      "PAY_AMT3     16625 non-null float64\n",
      "BILL_AMT1    16625 non-null float64\n",
      "BILL_AMT2    16625 non-null float64\n",
      "BILL_AMT3    16625 non-null float64\n",
      "dtypes: float64(7), int64(9)\n",
      "memory usage: 2.0 MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>TARGET</th>\n",
       "      <th>AGE</th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>SEX</th>\n",
       "      <th>PAY_1</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>BILL_AMT1</th>\n",
       "      <th>BILL_AMT2</th>\n",
       "      <th>BILL_AMT3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>16625.000000</td>\n",
       "      <td>16625.000000</td>\n",
       "      <td>16625.000000</td>\n",
       "      <td>16625.000000</td>\n",
       "      <td>16625.000000</td>\n",
       "      <td>16625.000000</td>\n",
       "      <td>16625.000000</td>\n",
       "      <td>16625.000000</td>\n",
       "      <td>16625.000000</td>\n",
       "      <td>16625.000000</td>\n",
       "      <td>16625.000000</td>\n",
       "      <td>16625.000000</td>\n",
       "      <td>16625.000000</td>\n",
       "      <td>16625.000000</td>\n",
       "      <td>16625.000000</td>\n",
       "      <td>16625.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8313.000000</td>\n",
       "      <td>0.398496</td>\n",
       "      <td>43.325714</td>\n",
       "      <td>157234.045113</td>\n",
       "      <td>1.476932</td>\n",
       "      <td>2.117534</td>\n",
       "      <td>1.588752</td>\n",
       "      <td>0.482226</td>\n",
       "      <td>0.430256</td>\n",
       "      <td>0.397293</td>\n",
       "      <td>5175.054075</td>\n",
       "      <td>4973.786105</td>\n",
       "      <td>4830.003368</td>\n",
       "      <td>50720.634827</td>\n",
       "      <td>48815.920662</td>\n",
       "      <td>46471.030556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4799.368448</td>\n",
       "      <td>0.489603</td>\n",
       "      <td>8.774694</td>\n",
       "      <td>124860.110928</td>\n",
       "      <td>0.523590</td>\n",
       "      <td>0.791191</td>\n",
       "      <td>0.492075</td>\n",
       "      <td>0.835516</td>\n",
       "      <td>0.881835</td>\n",
       "      <td>0.853110</td>\n",
       "      <td>15033.589318</td>\n",
       "      <td>14867.362888</td>\n",
       "      <td>15646.002915</td>\n",
       "      <td>73365.449060</td>\n",
       "      <td>70753.129768</td>\n",
       "      <td>68182.984755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-165580.000000</td>\n",
       "      <td>-69777.000000</td>\n",
       "      <td>-61506.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4157.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>566.000000</td>\n",
       "      <td>451.000000</td>\n",
       "      <td>306.000000</td>\n",
       "      <td>3491.000000</td>\n",
       "      <td>2997.000000</td>\n",
       "      <td>2550.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>8313.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>120000.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>1637.000000</td>\n",
       "      <td>21943.000000</td>\n",
       "      <td>20987.000000</td>\n",
       "      <td>19954.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>12469.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>230000.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>4696.000000</td>\n",
       "      <td>4025.000000</td>\n",
       "      <td>65903.000000</td>\n",
       "      <td>62725.000000</td>\n",
       "      <td>59111.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>16625.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>800000.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>505000.000000</td>\n",
       "      <td>384986.000000</td>\n",
       "      <td>508229.000000</td>\n",
       "      <td>746814.000000</td>\n",
       "      <td>646770.000000</td>\n",
       "      <td>693131.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ID        TARGET           AGE      LIMIT_BAL      MARRIAGE  \\\n",
       "count  16625.000000  16625.000000  16625.000000   16625.000000  16625.000000   \n",
       "mean    8313.000000      0.398496     43.325714  157234.045113      1.476932   \n",
       "std     4799.368448      0.489603      8.774694  124860.110928      0.523590   \n",
       "min        1.000000      0.000000     19.000000   10000.000000      1.000000   \n",
       "25%     4157.000000      0.000000     37.000000   50000.000000      1.000000   \n",
       "50%     8313.000000      0.000000     42.000000  120000.000000      1.000000   \n",
       "75%    12469.000000      1.000000     49.000000  230000.000000      2.000000   \n",
       "max    16625.000000      1.000000     72.000000  800000.000000      3.000000   \n",
       "\n",
       "          EDUCATION           SEX         PAY_1         PAY_2         PAY_3  \\\n",
       "count  16625.000000  16625.000000  16625.000000  16625.000000  16625.000000   \n",
       "mean       2.117534      1.588752      0.482226      0.430256      0.397293   \n",
       "std        0.791191      0.492075      0.835516      0.881835      0.853110   \n",
       "min        1.000000      1.000000      0.000000      0.000000      0.000000   \n",
       "25%        2.000000      1.000000      0.000000      0.000000      0.000000   \n",
       "50%        2.000000      2.000000      0.000000      0.000000      0.000000   \n",
       "75%        3.000000      2.000000      1.000000      0.000000      0.000000   \n",
       "max        4.000000      2.000000      4.000000      4.000000      4.000000   \n",
       "\n",
       "            PAY_AMT1       PAY_AMT2       PAY_AMT3      BILL_AMT1  \\\n",
       "count   16625.000000   16625.000000   16625.000000   16625.000000   \n",
       "mean     5175.054075    4973.786105    4830.003368   50720.634827   \n",
       "std     15033.589318   14867.362888   15646.002915   73365.449060   \n",
       "min         0.000000       0.000000       0.000000 -165580.000000   \n",
       "25%       566.000000     451.000000     306.000000    3491.000000   \n",
       "50%      2000.000000    2000.000000    1637.000000   21943.000000   \n",
       "75%      5000.000000    4696.000000    4025.000000   65903.000000   \n",
       "max    505000.000000  384986.000000  508229.000000  746814.000000   \n",
       "\n",
       "           BILL_AMT2      BILL_AMT3  \n",
       "count   16625.000000   16625.000000  \n",
       "mean    48815.920662   46471.030556  \n",
       "std     70753.129768   68182.984755  \n",
       "min    -69777.000000  -61506.000000  \n",
       "25%      2997.000000    2550.000000  \n",
       "50%     20987.000000   19954.000000  \n",
       "75%     62725.000000   59111.000000  \n",
       "max    646770.000000  693131.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Quick Look\n",
    "kredit.shape\n",
    "kredit.info()\n",
    "kredit.head(5)\n",
    "kredit.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%   EXPLORATORY DATA\n",
    "#Histogram\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(121)\n",
    "plt.hist(kredit['AGE'],bins=10)\n",
    "plt.title('AGE',size=15)\n",
    "plt.subplot(122)\n",
    "plt.hist(kredit['LIMIT_BAL'],bins=15)\n",
    "plt.title('LIMIT BAL',size=15)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(121)\n",
    "plt.hist(kredit['PAY_AMT1'],bins=50)\n",
    "plt.title('Pay January',size=15)\n",
    "plt.subplot(122)\n",
    "plt.hist(kredit['BILL_AMT1'],bins=50)\n",
    "plt.title('Bill January',size=15)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(131)\n",
    "plt.hist(kredit['PAY_AMT1'].apply(np.cbrt),bins=15)\n",
    "plt.title('Pay January',size=15)\n",
    "plt.subplot(132)\n",
    "plt.hist(kredit['PAY_AMT2'].apply(np.cbrt),bins=15)\n",
    "plt.title('Pay February',size=15)\n",
    "plt.subplot(133)\n",
    "plt.hist(kredit['PAY_AMT3'].apply(np.cbrt),bins=15)\n",
    "plt.title('Pay March',size=15)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.subplot(131)\n",
    "plt.hist(kredit['BILL_AMT1'].apply(np.cbrt),bins=15)\n",
    "plt.title('Bill January',size=15)\n",
    "plt.subplot(132)\n",
    "plt.hist(kredit['BILL_AMT2'].apply(np.cbrt),bins=15)\n",
    "plt.title('Bill February',size=15)\n",
    "plt.subplot(133)\n",
    "plt.hist(kredit['BILL_AMT3'].apply(np.cbrt),bins=15)\n",
    "plt.title('Bill March',size=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Barplot\n",
    "plt.figure(figsize=(10,5))\n",
    "marriage= kredit['MARRIAGE'].value_counts().sort_index().plot.bar(rot=0)\n",
    "plt.title('Marriage',size=15)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "edu= kredit['EDUCATION'].value_counts().sort_index().plot.bar(rot=0)\n",
    "plt.title('Education',size=15)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "gender= kredit['SEX'].value_counts().sort_index().plot.bar(rot=0)\n",
    "plt.title('Sex',size=15)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(131)\n",
    "pay0= kredit['PAY_1'].value_counts().sort_index().plot.bar(rot=0)\n",
    "plt.title('January Payment Status',size=15)\n",
    "plt.subplot(132)\n",
    "pay2= kredit['PAY_2'].value_counts().sort_index().plot.bar(rot=0)\n",
    "plt.title('February Payment Status',size=15)\n",
    "plt.subplot(133)\n",
    "pay3= kredit['PAY_3'].value_counts().sort_index().plot.bar(rot=0)\n",
    "plt.title('March Payment Status',size=15)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Target\n",
    "plt.figure(figsize=(7,5))\n",
    "target= kredit['TARGET'].value_counts(normalize=True).plot.bar(rot=0)\n",
    "plt.title('Target',size=15)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Outliers\n",
    "col_list=['AGE','LIMIT_BAL','PAY_AMT1','PAY_AMT2','PAY_AMT3','BILL_AMT1','BILL_AMT2','BILL_AMT3']\n",
    "numkredit = kredit[kredit.columns[kredit.columns.isin(col_list)]]\n",
    "plt.figure(figsize=(10,5))\n",
    "numkredit.boxplot(sym='r*',grid=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#NumVar vs Target\n",
    "kreditbar = kredit.copy(deep=True)\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(121)\n",
    "kreditbar.groupby('TARGET').AGE.plot.density(alpha=0.5, legend=True)\n",
    "plt.title('AGE',size=15)\n",
    "plt.subplot(122)\n",
    "kreditbar.groupby('TARGET').LIMIT_BAL.plot.density(alpha=0.5, legend=True)\n",
    "plt.title('LIMIT BAL',size=15)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(121)\n",
    "kreditbar.groupby('TARGET').PAY_AMT1.plot.density(alpha=0.5, legend=True)\n",
    "plt.title('Pay January',size=15)\n",
    "plt.subplot(122)\n",
    "kreditbar.groupby('TARGET').BILL_AMT1.plot.density(alpha=0.5, legend=True)\n",
    "plt.title('Bill January',size=15)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(131)\n",
    "kreditbar['PAY_AMT1']=np.cbrt(kreditbar['PAY_AMT1'])\n",
    "kreditbar.groupby('TARGET').PAY_AMT1.plot.density(alpha=0.5, legend=True)\n",
    "plt.title('Pay January',size=15)\n",
    "plt.subplot(132)\n",
    "kreditbar['PAY_AMT2']=np.cbrt(kreditbar['PAY_AMT2'])\n",
    "kreditbar.groupby('TARGET').PAY_AMT2.plot.density(alpha=0.5, legend=True)\n",
    "plt.title('Pay February',size=15)\n",
    "plt.subplot(133)\n",
    "kreditbar['PAY_AMT3']=np.cbrt(kreditbar['PAY_AMT3'])\n",
    "kreditbar.groupby('TARGET').PAY_AMT3.plot.density(alpha=0.5, legend=True)\n",
    "plt.title('Pay March',size=15)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(131)\n",
    "kreditbar['BILL_AMT1']=np.cbrt(kreditbar['BILL_AMT1'])\n",
    "kreditbar.groupby('TARGET').BILL_AMT1.plot.density(alpha=0.5, legend=True)\n",
    "plt.title('Bill January',size=15)\n",
    "plt.subplot(132)\n",
    "kreditbar['BILL_AMT2']=np.cbrt(kreditbar['BILL_AMT2'])\n",
    "kreditbar.groupby('TARGET').BILL_AMT2.plot.density(alpha=0.5, legend=True)\n",
    "plt.title('Bill February',size=15)\n",
    "plt.subplot(133)\n",
    "kreditbar['BILL_AMT3']=np.cbrt(kreditbar['BILL_AMT3'])\n",
    "kreditbar.groupby('TARGET').BILL_AMT3.plot.density(alpha=0.5, legend=True)\n",
    "plt.title('Bill March',size=15)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0xa0aa0f0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CatVar vs Target\n",
    "mt=pd.crosstab(kredit['MARRIAGE'], kredit['TARGET'],normalize='index')\n",
    "mt.plot.bar(rot=0,stacked=True)\n",
    "et=pd.crosstab(kredit['EDUCATION'], kredit['TARGET'],normalize='index')\n",
    "et.plot.bar(rot=0,stacked=True)\n",
    "st=pd.crosstab(kredit['SEX'], kredit['TARGET'],normalize='index')\n",
    "st.plot.bar(rot=0,stacked=True)\n",
    "p1t=pd.crosstab(kredit['PAY_1'], kredit['TARGET'],normalize='index')\n",
    "p1t.plot.bar(rot=0,stacked=True)\n",
    "p2t=pd.crosstab(kredit['PAY_2'], kredit['TARGET'],normalize='index')\n",
    "p2t.plot.bar(rot=0,stacked=True)\n",
    "p3t=pd.crosstab(kredit['PAY_3'], kredit['TARGET'],normalize='index')\n",
    "p3t.plot.bar(rot=0,stacked=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%%%%%%%%%%%%%%%%%%%%%    ONE HOT ENCODER\n",
    "#\n",
    "kredit=pd.get_dummies(kredit, columns=['MARRIAGE', 'EDUCATION', 'SEX', 'PAY_1','PAY_2','PAY_3'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%%%%%%%%%%%%%%%%%%%%         RAW DATA MODELLING\n",
    "#Raw Data Splitting\n",
    "X=kredit.drop(['ID','TARGET'],1)\n",
    "Y = kredit['TARGET']\n",
    "train_X,test_X,train_y,test_y =train_test_split(X,Y,test_size=0.2,random_state=123)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#KFold Cross Validation\n",
    "kfold = KFold(n_splits=10, random_state=123)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.63338345864661671"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "logreg = LogisticRegression(random_state = 123)\n",
    "results = cross_val_score(logreg, train_X, train_y, cv=kfold)\n",
    "results.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix : \n",
      " [[1444  609]\n",
      " [ 577  695]]\n",
      "Accuracy :  0.643308270677\n",
      "Sensitivity :  0.546383647799\n",
      "Specificity :  0.703360935217\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "logreg.fit(train_X, train_y)\n",
    "logregpred = logreg.predict(test_X)\n",
    "\n",
    "cm1 = confusion_matrix(test_y,logregpred)\n",
    "\n",
    "total1=sum(sum(cm1))\n",
    "accuracy1 = (cm1[0,0]+cm1[1,1])/total1\n",
    "sensitivity1 = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
    "specificity1 = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
    "\n",
    "print('Confusion Matrix : \\n', cm1)\n",
    "print('Accuracy : ', accuracy1)\n",
    "print('Sensitivity : ', sensitivity1 )\n",
    "print('Specificity : ', specificity1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83195488721804511"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Decision Tree\n",
    "decisiontree = DecisionTreeClassifier(random_state = 123)\n",
    "results = cross_val_score(decisiontree, train_X, train_y, cv=kfold)\n",
    "results.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix : \n",
      " [[1746  307]\n",
      " [ 292  980]]\n",
      "Accuracy :  0.81984962406\n",
      "Sensitivity :  0.770440251572\n",
      "Specificity :  0.850462737457\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "decisiontree.fit(train_X, train_y)\n",
    "dtpred = decisiontree.predict(test_X)\n",
    "\n",
    "cm1 = confusion_matrix(test_y,dtpred)\n",
    "\n",
    "total1=sum(sum(cm1))\n",
    "accuracy1 = (cm1[0,0]+cm1[1,1])/total1\n",
    "sensitivity1 = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
    "specificity1 = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
    "\n",
    "print('Confusion Matrix : \\n', cm1)\n",
    "print('Accuracy : ', accuracy1)\n",
    "print('Sensitivity : ', sensitivity1 )\n",
    "print('Specificity : ', specificity1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%%%%%%%%%%%%%%%%%%%        FEATURE ENGINEERING\n",
    "# Merubah kategori 2, 3 dan 4 menjadi 1\n",
    "kredit1['PAY_1'] = kredit1['PAY_1'].replace([2, 3, 4], 1)\n",
    "kredit1['PAY_2'] = kredit1['PAY_2'].replace([2, 3, 4], 1)\n",
    "kredit1['PAY_3'] = kredit1['PAY_3'].replace([2, 3, 4], 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# One Hot Encoder\n",
    "kredit1=pd.get_dummies(kredit1, columns=['MARRIAGE', 'EDUCATION', 'SEX', 'PAY_1','PAY_2','PAY_3'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Diskretisasi\n",
    "kredit1['AGE']=pd.cut(kredit1.AGE,[10,30,40,50,60,80], labels=False)\n",
    "kredit1['LIMIT_BAL']=pd.cut(kredit1.LIMIT_BAL,[-np.inf,50000,100000,150000,200000,250000,300000,np.inf], labels=False)\n",
    "kredit1['PAY_AMT1']=pd.cut(kredit1.PAY_AMT1,[-np.inf,500,1000,2000,2500,3000,3500,4000,5000,np.inf], labels=False)\n",
    "kredit1['PAY_AMT2']=pd.cut(kredit1.PAY_AMT2,[-np.inf,500,1000,2000,2500,3000,3500,4000,5000,np.inf], labels=False)\n",
    "kredit1['PAY_AMT3']=pd.cut(kredit1.PAY_AMT3,[-np.inf,500,1000,2000,2500,3000,3500,4000,5000,np.inf], labels=False)\n",
    "kredit1['BILL_AMT1']=pd.cut(kredit1.BILL_AMT1,[-np.inf,5000,15000,25000,35000,45000,55000,65000,np.inf], labels=False)\n",
    "kredit1['BILL_AMT2']=pd.cut(kredit1.BILL_AMT2,[-np.inf,5000,15000,25000,35000,45000,55000,65000,np.inf], labels=False)\n",
    "kredit1['BILL_AMT3']=pd.cut(kredit1.BILL_AMT3,[-np.inf,5000,15000,25000,35000,45000,55000,65000,np.inf], labels=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Outliers setelah Feature Engineering\n",
    "col_list1=['AGE','LIMIT_BAL','PAY_AMT1','PAY_AMT2','PAY_AMT3','BILL_AMT1','BILL_AMT2','BILL_AMT3']\n",
    "numkredit = kredit1[kredit1.columns[kredit1.columns.isin(col_list1)]]\n",
    "plt.figure(figsize=(10,5))\n",
    "numkredit.boxplot(sym='r*',grid=False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%%%%%%%%%%%%%%%%%%          FEATURE ENGINEERING DATA MODELLING\n",
    "#Diskrete Data Splitting\n",
    "X1=kredit1.drop(['ID','TARGET'],1)\n",
    "Y1= kredit1['TARGET']\n",
    "train_X1,test_X1,train_y1,test_y1 =train_test_split(X1,Y1,test_size=0.2,random_state=123)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.73969924812030086"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "logreg1 = LogisticRegression(random_state = 123)\n",
    "results = cross_val_score(logreg1, train_X1, train_y1, cv=kfold)\n",
    "results.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix : \n",
      " [[1738  315]\n",
      " [ 533  739]]\n",
      "Accuracy :  0.744962406015\n",
      "Sensitivity :  0.580974842767\n",
      "Specificity :  0.846566000974\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "logreg1.fit(train_X1, train_y1)\n",
    "logregpred1 = logreg1.predict(test_X1)\n",
    "\n",
    "cm1 = confusion_matrix(test_y1,logregpred1)\n",
    "\n",
    "total1=sum(sum(cm1))\n",
    "accuracy1 = (cm1[0,0]+cm1[1,1])/total1\n",
    "sensitivity1 = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
    "specificity1 = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
    "\n",
    "print('Confusion Matrix : \\n', cm1)\n",
    "print('Accuracy : ', accuracy1)\n",
    "print('Sensitivity : ', sensitivity1 )\n",
    "print('Specificity : ', specificity1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.77706766917293235"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DecTree\n",
    "decisiontree1 = DecisionTreeClassifier(random_state = 123)\n",
    "results = cross_val_score(decisiontree1, train_X1, train_y1, cv=kfold)\n",
    "results.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix : \n",
      " [[1652  401]\n",
      " [ 384  888]]\n",
      "Accuracy :  0.763909774436\n",
      "Sensitivity :  0.698113207547\n",
      "Specificity :  0.80467608378\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "decisiontree1.fit(train_X1, train_y1)\n",
    "dtpred1 = decisiontree1.predict(test_X1)\n",
    "\n",
    "cm1 = confusion_matrix(test_y1,dtpred1)\n",
    "\n",
    "total1=sum(sum(cm1))\n",
    "accuracy1 = (cm1[0,0]+cm1[1,1])/total1\n",
    "sensitivity1 = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
    "specificity1 = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
    "\n",
    "print('Confusion Matrix : \\n', cm1)\n",
    "print('Accuracy : ', accuracy1)\n",
    "print('Sensitivity : ', sensitivity1 )\n",
    "print('Specificity : ', specificity1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'C': 0.01}, 0.63511278195488718)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%%%%%%%%%%%%%%%%%%%        TUNING PARAMETER RAW DATA\n",
    "#Reglog (C)\n",
    "param_test = {'C': [0.001,0.01,0.1,1,10,100]}\n",
    "gsearch = GridSearchCV(estimator = LogisticRegression(random_state = 123), param_grid = param_test, scoring='accuracy', cv=10)\n",
    "gsearch.fit(train_X, train_y)\n",
    "gsearch.best_params_, gsearch.best_score_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'criterion': 'entropy', 'min_samples_split': 70}, 0.85233082706766916)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#DecTree (criterion, min_samples_split)\n",
    "param_test1 = {'criterion': ['gini', 'entropy'],\n",
    "              'min_samples_split': range(10,101,10)}\n",
    "gsearch1 = GridSearchCV(estimator = DecisionTreeClassifier(random_state = 123), param_grid = param_test1, scoring='accuracy',cv=10)\n",
    "gsearch1.fit(train_X,train_y)\n",
    "gsearch1.best_params_, gsearch1.best_score_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'max_depth': 13, 'min_samples_leaf': 30}, 0.85511278195488727)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DecTree (max_depth, min_samples_leaf)\n",
    "param_test2 = {'max_depth': range(5,16,2),\n",
    "              'min_samples_leaf': range(30,71,10)}\n",
    "gsearch2 = GridSearchCV(estimator = DecisionTreeClassifier(criterion='entropy', min_samples_leaf=70,random_state = 123), param_grid = param_test2, scoring='accuracy',cv=10)\n",
    "gsearch2.fit(train_X,train_y)\n",
    "gsearch2.best_params_, gsearch2.best_score_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix : \n",
      " [[1411  642]\n",
      " [ 565  707]]\n",
      "Accuracy :  0.636992481203\n",
      "Sensitivity :  0.555817610063\n",
      "Specificity :  0.687286897224\n"
     ]
    }
   ],
   "source": [
    "#%%%%%%%%%%%%%%%%%%       BEST MODEL FOR RAW DATA\n",
    "#Reglog\n",
    "bestrl = LogisticRegression(C=0.01,random_state = 123)\n",
    "bestrl.fit(train_X, train_y)\n",
    "bestrlpred = bestrl.predict(test_X)\n",
    "\n",
    "cm1 = confusion_matrix(test_y,bestrlpred)\n",
    "\n",
    "total1=sum(sum(cm1))\n",
    "accuracy1 = (cm1[0,0]+cm1[1,1])/total1\n",
    "sensitivity1 = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
    "specificity1 = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
    "\n",
    "print('Confusion Matrix : \\n', cm1)\n",
    "print('Accuracy : ', accuracy1)\n",
    "print('Sensitivity : ', sensitivity1 )\n",
    "print('Specificity : ', specificity1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix : \n",
      " [[1800  253]\n",
      " [ 268 1004]]\n",
      "Accuracy :  0.843308270677\n",
      "Sensitivity :  0.789308176101\n",
      "Specificity :  0.876765708719\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree\n",
    "bestdt = DecisionTreeClassifier(criterion='entropy',min_samples_split=70, max_depth=13, min_samples_leaf=30 ,random_state = 123)\n",
    "bestdt.fit(train_X, train_y)\n",
    "bestdtpred = bestdt.predict(test_X)\n",
    "\n",
    "cm1 = confusion_matrix(test_y,bestdtpred)\n",
    "\n",
    "total1=sum(sum(cm1))\n",
    "accuracy1 = (cm1[0,0]+cm1[1,1])/total1\n",
    "sensitivity1 = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
    "specificity1 = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
    "\n",
    "print('Confusion Matrix : \\n', cm1)\n",
    "print('Accuracy : ', accuracy1)\n",
    "print('Sensitivity : ', sensitivity1 )\n",
    "print('Specificity : ', specificity1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'C': 0.1}, 0.73992481203007521)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%%%%%%%%%%%%%%%%%%%        TUNING PARAMETER FEATURE ENGINEERING DATA\n",
    "#Reglog (C)\n",
    "param_test = {'C': [0.001,0.01,0.1,1,10,100]}\n",
    "gsearch = GridSearchCV(estimator = LogisticRegression(random_state = 123), param_grid = param_test, scoring='accuracy', cv=10)\n",
    "gsearch.fit(train_X1, train_y1)\n",
    "gsearch.best_params_, gsearch.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'criterion': 'entropy', 'min_samples_split': 60}, 0.80842105263157893)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#DecTree (criterion, min_samples_split)\n",
    "param_test1 = {'criterion': ['gini', 'entropy'],\n",
    "              'min_samples_split': range(10,101,10)}\n",
    "gsearch1 = GridSearchCV(estimator = DecisionTreeClassifier(random_state = 123), param_grid = param_test1, scoring='accuracy',cv=10)\n",
    "gsearch1.fit(train_X1,train_y1)\n",
    "gsearch1.best_params_, gsearch1.best_score_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'max_depth': 13, 'min_samples_leaf': 40}, 0.80218045112781955)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#DecTree (max_depth, min_samples_leaf)\n",
    "param_test2 = {'max_depth': range(5,16,2),\n",
    "              'min_samples_leaf': range(30,71,10)}\n",
    "gsearch2 = GridSearchCV(estimator = DecisionTreeClassifier(criterion='entropy', min_samples_leaf=60,random_state = 123), param_grid = param_test2, scoring='accuracy',cv=10)\n",
    "gsearch2.fit(train_X1,train_y1)\n",
    "gsearch2.best_params_, gsearch2.best_score_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix : \n",
      " [[1739  314]\n",
      " [ 534  738]]\n",
      "Accuracy :  0.744962406015\n",
      "Sensitivity :  0.580188679245\n",
      "Specificity :  0.847053093035\n"
     ]
    }
   ],
   "source": [
    "#%%%%%%%%%%%%%%%%%%       BEST MODEL FOR FEATURE ENGINEERING DATA\n",
    "#Reglog\n",
    "bestrl = LogisticRegression(C=0.1,random_state = 123)\n",
    "bestrl.fit(train_X1, train_y1)\n",
    "bestrlpred = bestrl.predict(test_X1)\n",
    "\n",
    "cm1 = confusion_matrix(test_y1,bestrlpred)\n",
    "\n",
    "total1=sum(sum(cm1))\n",
    "accuracy1 = (cm1[0,0]+cm1[1,1])/total1\n",
    "sensitivity1 = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
    "specificity1 = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
    "\n",
    "print('Confusion Matrix : \\n', cm1)\n",
    "print('Accuracy : ', accuracy1)\n",
    "print('Sensitivity : ', sensitivity1 )\n",
    "print('Specificity : ', specificity1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix : \n",
      " [[1778  275]\n",
      " [ 380  892]]\n",
      "Accuracy :  0.803007518797\n",
      "Sensitivity :  0.701257861635\n",
      "Specificity :  0.86604968339\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree\n",
    "bestdt = DecisionTreeClassifier(criterion='entropy',min_samples_split=60, max_depth=13, min_samples_leaf=40 ,random_state = 123)\n",
    "bestdt.fit(train_X1, train_y1)\n",
    "bestdtpred = bestdt.predict(test_X1)\n",
    "\n",
    "cm1 = confusion_matrix(test_y1,bestdtpred)\n",
    "\n",
    "total1=sum(sum(cm1))\n",
    "accuracy1 = (cm1[0,0]+cm1[1,1])/total1\n",
    "sensitivity1 = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
    "specificity1 = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
    "\n",
    "print('Confusion Matrix : \\n', cm1)\n",
    "print('Accuracy : ', accuracy1)\n",
    "print('Sensitivity : ', sensitivity1 )\n",
    "print('Specificity : ', specificity1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix : \n",
      " [[1878  175]\n",
      " [ 243 1029]]\n",
      "Accuracy :  0.874285714286\n",
      "Sensitivity :  0.808962264151\n",
      "Specificity :  0.91475888943\n"
     ]
    }
   ],
   "source": [
    "#%%%%%%%%%%%%%%%%%%%         ADVANCE MODEL\n",
    "#Raw Data Gradient Boosting\n",
    "gbm = GradientBoostingClassifier(random_state = 123)\n",
    "gbm.fit(train_X, train_y)\n",
    "gbmpred = gbm.predict(test_X)\n",
    "\n",
    "cm1 = confusion_matrix(test_y,gbmpred)\n",
    "\n",
    "total1=sum(sum(cm1))\n",
    "accuracy1 = (cm1[0,0]+cm1[1,1])/total1\n",
    "sensitivity1 = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
    "specificity1 = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
    "\n",
    "print('Confusion Matrix : \\n', cm1)\n",
    "print('Accuracy : ', accuracy1)\n",
    "print('Sensitivity : ', sensitivity1 )\n",
    "print('Specificity : ', specificity1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix : \n",
      " [[1850  203]\n",
      " [ 323  949]]\n",
      "Accuracy :  0.841804511278\n",
      "Sensitivity :  0.74606918239\n",
      "Specificity :  0.901120311739\n"
     ]
    }
   ],
   "source": [
    "#Raw Data Random Forest\n",
    "rf = RandomForestClassifier(random_state = 123)\n",
    "rf.fit(train_X, train_y)\n",
    "rfpred = rf.predict(test_X)\n",
    "\n",
    "cm1 = confusion_matrix(test_y,rfpred)\n",
    "\n",
    "total1=sum(sum(cm1))\n",
    "accuracy1 = (cm1[0,0]+cm1[1,1])/total1\n",
    "sensitivity1 = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
    "specificity1 = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
    "\n",
    "print('Confusion Matrix : \\n', cm1)\n",
    "print('Accuracy : ', accuracy1)\n",
    "print('Sensitivity : ', sensitivity1 )\n",
    "print('Specificity : ', specificity1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix : \n",
      " [[1839  214]\n",
      " [ 359  913]]\n",
      "Accuracy :  0.827669172932\n",
      "Sensitivity :  0.717767295597\n",
      "Specificity :  0.895762299075\n"
     ]
    }
   ],
   "source": [
    "#Feature Engineering Data Gradient Boosting\n",
    "gbm1 = GradientBoostingClassifier(random_state = 123, n_estimators = 100)\n",
    "gbm1.fit(train_X1, train_y1)\n",
    "gbmpred1 = gbm1.predict(test_X1)\n",
    "\n",
    "cm1 = confusion_matrix(test_y1,gbmpred1)\n",
    "\n",
    "total1=sum(sum(cm1))\n",
    "accuracy1 = (cm1[0,0]+cm1[1,1])/total1\n",
    "sensitivity1 = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
    "specificity1 = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
    "\n",
    "print('Confusion Matrix : \\n', cm1)\n",
    "print('Accuracy : ', accuracy1)\n",
    "print('Sensitivity : ', sensitivity1 )\n",
    "print('Specificity : ', specificity1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix : \n",
      " [[1779  274]\n",
      " [ 352  920]]\n",
      "Accuracy :  0.811729323308\n",
      "Sensitivity :  0.723270440252\n",
      "Specificity :  0.866536775451\n"
     ]
    }
   ],
   "source": [
    "#Feature Engineering Data Random Forest\n",
    "rf1 = RandomForestClassifier(random_state = 123, n_estimators= 100)\n",
    "rf1.fit(train_X1, train_y1)\n",
    "rfpred1 = rf1.predict(test_X1)\n",
    "\n",
    "cm1 = confusion_matrix(test_y1,rfpred1)\n",
    "\n",
    "total1=sum(sum(cm1))\n",
    "accuracy1 = (cm1[0,0]+cm1[1,1])/total1\n",
    "sensitivity1 = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
    "specificity1 = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
    "\n",
    "print('Confusion Matrix : \\n', cm1)\n",
    "print('Accuracy : ', accuracy1)\n",
    "print('Sensitivity : ', sensitivity1 )\n",
    "print('Specificity : ', specificity1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.07590548])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%        SUMMARY\n",
    "#Summary Reglog (menggunakan Feature Engineering Data)\n",
    "bestrl.intercept_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AGE</td>\n",
       "      <td>0.638749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LIMIT_BAL</td>\n",
       "      <td>-0.232242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PAY_AMT1</td>\n",
       "      <td>-0.037664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PAY_AMT2</td>\n",
       "      <td>-0.021996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PAY_AMT3</td>\n",
       "      <td>-0.035815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BILL_AMT1</td>\n",
       "      <td>-0.056483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BILL_AMT2</td>\n",
       "      <td>0.007311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>BILL_AMT3</td>\n",
       "      <td>0.079511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MARRIAGE_1</td>\n",
       "      <td>0.278696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MARRIAGE_2</td>\n",
       "      <td>-0.400665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>MARRIAGE_3</td>\n",
       "      <td>0.046064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>EDUCATION_1</td>\n",
       "      <td>-0.476182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>EDUCATION_2</td>\n",
       "      <td>-0.013269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>EDUCATION_3</td>\n",
       "      <td>0.404014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>EDUCATION_4</td>\n",
       "      <td>0.009531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>SEX_1</td>\n",
       "      <td>0.255130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>SEX_2</td>\n",
       "      <td>-0.331035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>PAY_1_0</td>\n",
       "      <td>-0.641533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>PAY_1_1</td>\n",
       "      <td>0.565627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>PAY_2_0</td>\n",
       "      <td>-0.196255</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         0\n",
       "0           AGE  0.638749\n",
       "1     LIMIT_BAL -0.232242\n",
       "2      PAY_AMT1 -0.037664\n",
       "3      PAY_AMT2 -0.021996\n",
       "4      PAY_AMT3 -0.035815\n",
       "5     BILL_AMT1 -0.056483\n",
       "6     BILL_AMT2  0.007311\n",
       "7     BILL_AMT3  0.079511\n",
       "8    MARRIAGE_1  0.278696\n",
       "9    MARRIAGE_2 -0.400665\n",
       "10   MARRIAGE_3  0.046064\n",
       "11  EDUCATION_1 -0.476182\n",
       "12  EDUCATION_2 -0.013269\n",
       "13  EDUCATION_3  0.404014\n",
       "14  EDUCATION_4  0.009531\n",
       "15        SEX_1  0.255130\n",
       "16        SEX_2 -0.331035\n",
       "17      PAY_1_0 -0.641533\n",
       "18      PAY_1_1  0.565627\n",
       "19      PAY_2_0 -0.196255"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# coef\n",
    "coef = pd.concat([pd.DataFrame(X1.columns),pd.DataFrame(np.transpose(bestrl.coef_))], axis = 1)\n",
    "coef.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DT Graph\n",
    "best1 = DecisionTreeClassifier(criterion='entropy',min_samples_split=60, max_depth=13, min_samples_leaf=2500 ,random_state = 123)\n",
    "best1.fit(train_X1, train_y1)\n",
    "export_graphviz(best1, out_file='D:/best1.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Open and copy 'best1.txt' to www.webgraphviz.com"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
